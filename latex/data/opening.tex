\documentclass{article}
\title{Survey of Opinion-oriented Event Tracking in Social Network}
\author{Ningping Wang}
\begin{document}
\maketitle

Online social networks, such as Facebook, Twitter, Weibo and Renren, have achieved great success in the past years. Now Facebook has over 1 billion users and Sina Weibo has about 59 million users. It's reported that people in US are spending their 16\% online time on Facebook, even more than Google (10\%). With the rapid growth of online social networks, information is produced at an amazing speed. More than 500 million tweets are sent everyday on average. people share their opinions about various events from the Olympics to commercial promotions. Each event consists of several aspects and people's interests and opinions are changing over time. Take the Olympics for example. The opening ceremony is mostly talked about in the first few days. Then with the event going on, different sport matches and athletes are talked about. When an athelete won a pedal, people will cheer for him. However, severval days later, he made a blunder and lost, people's opinion changed. Faced with the information overwhelming, we need a automatic way to track the event process and people's opinon. Given an event, we want to know, 1. What aspects does people interested in 2. How does people's interest and opinions evolve over time and 3. Who are the most influcial users in the discussion of the topic. And finally a flow chart visualization is helpful to demostrate the evolution process of the opinion.

Several classical research areas in data mining are closely related to the problem, such as opinion mining, topic modeling, event detection and tracking. 

\section {Opinion Mining}
Opinion mining aims to find out people's opinion about an {\em entity} from corpus like product reviews or blogs. An entity can be a product, service, event, topic, anything that can be evaluated. An entity can be represente as a combination of different aspects (or features). For example, for an mobile phone (entity), screen, battery, memory are three aspects. Given a collection of documents $D$, the objective of opinion definition is, opinion mining aims to extract entities, aspects, associated opinions and analyse their sentiment orientations. To get a high-level perspective of the whole corpus, an addition summary step is optional.

Aspect extraction is a foundametal step in aspected-based opinion mining and is closely related with our task. The first work in aspect extraction is a two-step unsupervised method \cite{hu2004mining}. First, find frequent nouns and noun phrases. Then, find infrequent aspects by using the relationships between aspects and known opinion words. The method base on the intuition that important aspects are talked about frequently and phrases which co-occur with opinions words often are likely to be aspects. Opinion words can be generated in two ways. The dictionary-based approach defines a seed set of opinion words and search their synonyms and antoyms in a dictionary WordNet. However, it fails to capture the characteristic that the same word can express different sentiment orientation in different domains. The corpus-based approach also uses a seet set. But it finds new words by exploiting syntactic or cooccurence patterns in a large corpus\cite{hatzivassiloglou1997predicting}. The aspect extraction and opinion words finding can reinforce each other. New-found opinion words provide hint for identifying new aspects, while new aspects result in more opinion words. So many following researches combine them in a unified framework. 

More unsuperived and supervised algorithms were proposed since then. Supervised methods treat aspect extraction as a classification problem. CRF is used in \cite{jakob2010extracting}. Jin et al. \cite{jin2009opinionminer} used a HMM based sequence tagging method to find entities and opinion words simultaneously. Su et al. \cite{su2008hidden} proposed a clustering-based method to find hidden association of opinion words and aspects. Topic models can also be used in aspect extraction. However, as Titov\cite{titov2008modeling} pointed out, plain LDA is not suitable for aspect extraction because it can't distinguish global topics (like hotels in China, hotels in America) and local topics( aspects of hotels). He proposed a multi-grain LDA (MG-LDA) to solve that problem. MG-LDA models global and local topics at the same time. Another way to solve that problem is to run LDA on sentence level \cite{brody2010unsupervised}. But the two methods mess opinion words and aspects together. Zhao et al, \cite{zhao2010jointly} proposed MaxEnt-LDA to model aspect and aspect-specific opinion words jointly.

To decide the sentiment orientation of an opinion, machine learning classification methods such as SVM and naive Bayesian can be used. However, lexicon-based method can caputure more subtle semantic elements of a opinion\cite{ding2008holistic}. For example, opinion shifters like negation words (not, never, none) and sarcasm, and but-clauses. 

\section {Evolutionary Topic Models}
LDA, first proposed by Blei et al,\cite{blei2003latent} has become the most popular topic modeling tool. In general, LDA is extended in three main directions. 1. Modeling more latent attributes like sentiment, social role, personal preference. 2. Incorporating inter-document relations. For example, relational LDA\cite{chang2009relational} on a citation network and author-topic LDA\cite{rosen2004author} on a author-document network. 3. Build time-aware topic model to model {\em topic evolution} in corpus, which we are most interested in.

The first try to model topic evolution with LDA is by Blei et al\cite{blei2006dynamic}. In their model, time is discretized and topic distributions satisfy Markov attribute. They chain prior $\alpha$ and $\beta$ in LDA with parameters in adjacent time slices using Gaussian distribution. A drawback of discrete-time model is we have to choose a suitable grain of time slices. In continuous dynamic topic model (cDTM) \cite{wang2012continuous}, Brownian motion is used instead of Gaussian distribution. To get rid of the Markov assumption, Wang \cite{wang2006topics} associated a Beta distribution of time with each topic to model topic popularity evolution, but topic distribtuions keep the same over time. Moreover, topic number is fixed over time. Topic birth and death are ignored. For example, at the dawn of artificial intelligence, areas like pattern recognition, natrual language processing are rarely talked about explicitly. However, they're now so important that PR and NLP should be seen as separate topics. So a {\em split} of a topic happens. A non-parametric version of dynamic topic model called Infinite Dynamic Topic Models (iDTM) is given by Ahmed \cite{ahmed2012timeline}. iDTM models each document using a hierarchical dirichlet process.

Visualization is a perfect way to demonstrate the evolution trend of topics. Liu composed several great visualization tools for rendering topic dynamics. TextFlow \cite{cui2011textflow} renders the whole corpus as a multi-branch flow. Each branch is a topic. Different branches can split or join each other, representing topic birth and death. And width of a flow indicates the popularity. It was further developed into a interactive analysing tool \cite{liu2009interactive}.

\section {Event Tracking and Burstiness detection}
The task of Event tracking is about discovering temporal intensities of events in text streams such as weblogs or newswires. Event detection and tracking is closely related with dynamic topic modeling and share methods in common. However, event detection has its own features. First, topic evolution analysis is usually done off-line. We accumulate data over a time window and run algorithms on whole data set. While event detection is executed at the time new data comes, aka {\em on-line}. Second, topic model focuses on topics that are heavily talked about. While event detection emphasizes the {\em burstiness} more. A new event may not be talked about intensively now, but its occurence rises rapidly in a short time. 

Variations of LDA are used in event tracking. AlSumait\cite{alsumait2008line} proposes an on-line version of LDA to track the event. Ha-Thuc et al. proposed a relevance-based topic model for news event tracking\cite{ha2009relevance}.   
However, apart from LDA, many other models can be used. Leskovec et al. \cite{leskovec2009meme} studied a novel problem of meme-tracking. meme is a quoted text which vaires during spreading over the web. They adopted a clustering method to group variants of a meme together and analyisis global and local intensity.

Term burstiness has been extensively researched as a mechanism to address new event detection. Kleinberg \cite{kleinberg2003bursty} used a state machine to model the burtiness and inspired most following work. Lappas et al. \cite{lappas2009burstiness} further explore how burtiness can enhance document searching.


\bibliographystyle{plain} 
\bibliography{opening.bib}
\end{document}


